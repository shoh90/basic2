import streamlit as st
import pandas as pd
import requests
from bs4 import BeautifulSoup

st.set_page_config(page_title="ì§€ì›ì‚¬ì—… ì•ˆë‚´", layout="wide", page_icon="ğŸ“")

st.title("ğŸ“ ì œì£¼ ë†ì—… ì§€ì›ì‚¬ì—… ì•ˆë‚´")

# í¬ë¡¤ë§ ëŒ€ìƒ URL & ì œë„ëª…
targets = [
    {"url": "https://agri.jeju.go.kr", "ì œë„ëª…": "ê°ê·¤ì› ê°„ë²Œì‚¬ì—…"},
    {"url": "https://www.jeju.go.kr", "ì œë„ëª…": "ë…¸ì§€ê°ê·¤ ê°€ê²©ì•ˆì •ê´€ë¦¬ì œ"},
    {"url": "https://www.bizinfo.go.kr/web/lay1/bbs/S1T122C128/AS/74/view.do?pblancId=PBLN_000000000102468", "ì œë„ëª…": "FTAê¸°ê¸ˆ ê³¼ìˆ˜(ê°ê·¤) ê³ í’ˆì§ˆ ì‹œì„¤í˜„ëŒ€í™” ì§€ì›ì‚¬ì—…"},
    {"url": "https://blog.naver.com/happyjejudo/223773326101", "ì œë„ëª…": "ê°ê·¤ ì „ì •ê°€ì§€ íŒŒì‡„ ì§€ì›"},
    {"url": "https://blog.naver.com/happyjejudo/223325069685", "ì œë„ëª…": "ë†ì—…ê¸°ìˆ ë³´ê¸‰ ì‹œë²”ì‚¬ì—…"},
]

# âœ… í¬ë¡¤ë§ í•¨ìˆ˜ (ìºì‹œ ì ìš©)
@st.cache_data(ttl=3600)
def fetch_support_programs():
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/134.0.0.0 Whale/4.31.304.16 Safari/537.36"
    }

    data = []

    for item in targets:
        url, title = item["url"], item["ì œë„ëª…"]
        try:
            res = requests.get(url, headers=headers, timeout=10)
            res.raise_for_status()
            soup = BeautifulSoup(res.text, "html.parser")

            texts = soup.get_text(separator='\n')
            cleaned = "\n".join([line.strip() for line in texts.splitlines() if line.strip()])
            summary = cleaned[:200] + "..."

            if 'ì œì£¼ì‹œ' in cleaned:
                ê¸°ê´€ = "ì œì£¼ì‹œ"
            elif 'ì„œê·€í¬ì‹œ' in cleaned:
                ê¸°ê´€ = "ì„œê·€í¬ì‹œ"
            elif any(x in cleaned for x in ['ë†ì‹í’ˆë¶€', 'ë†ë¦¼ì¶•ì‚°ì‹í’ˆë¶€']):
                ê¸°ê´€ = "ë†ë¦¼ì¶•ì‚°ì‹í’ˆë¶€"
            elif 'ë†ì—…ê¸°ìˆ ì›' in cleaned:
                ê¸°ê´€ = "ì œì£¼íŠ¹ë³„ìì¹˜ë„ ë†ì—…ê¸°ìˆ ì›"
            else:
                ê¸°ê´€ = "ì œì£¼íŠ¹ë³„ìì¹˜ë„ì²­"

            data.append({
                "ì§€ì› ì œë„ ì´ë¦„": title,
                "ì£¼ìš” ë‚´ìš©": summary,
                "ì£¼ê´€ ê¸°ê´€": ê¸°ê´€,
                "ì¶œì²˜": url
            })

        except Exception as e:
            st.error(f"â— {title} : ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ ({e})")
            data.append({
                "ì§€ì› ì œë„ ì´ë¦„": title,
                "ì£¼ìš” ë‚´ìš©": "ë‚´ìš©ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "ì£¼ê´€ ê¸°ê´€": "ì •ë³´ ì—†ìŒ",
                "ì¶œì²˜": url
            })

    return pd.DataFrame(data)

# âœ… ë°ì´í„° ë¡œë”©
df = fetch_support_programs()

# âœ… ì¹´ë“œí˜• ë¦¬ìŠ¤íŠ¸ (expander í˜•íƒœ)
for _, row in df.iterrows():
    with st.expander(f"âœ… {row['ì§€ì› ì œë„ ì´ë¦„']} ({row['ì£¼ê´€ ê¸°ê´€']})"):
        st.write(row['ì£¼ìš” ë‚´ìš©'])
        st.markdown(f"[ğŸ”— ìì„¸íˆ ë³´ê¸°]({row['ì¶œì²˜']})")

# âœ… ì „ì²´ í‘œ ë³´ê¸°
st.divider()
with st.expander("ì „ì²´ ëª©ë¡ ë³´ê¸° (í‘œ í˜•íƒœ)"):
    st.dataframe(df, use_container_width=True)
